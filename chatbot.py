"""
Omani Mental Health Chatbot - Enhanced with Dual-Model Validation
Handles the AI conversation logic with therapeutic-grade safety features
"""

import os
import re
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from dotenv import load_dotenv

# Try importing LangChain components with fallbacks
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    print("Warning: langchain_openai not available, using direct OpenAI API")
    ChatOpenAI = None

try:
    from langchain_anthropic import ChatAnthropic
except ImportError:
    print("Warning: langchain_anthropic not available")
    ChatAnthropic = None

try:
    from langchain.schema import HumanMessage, AIMessage, SystemMessage
except ImportError:
    # Fallback for basic message structure
    class BaseMessage:
        def __init__(self, content: str):
            self.content = content
    
    class HumanMessage(BaseMessage):
        pass
    
    class AIMessage(BaseMessage):
        pass
    
    class SystemMessage(BaseMessage):
        pass

# Direct API imports as fallback
try:
    import openai
except ImportError:
    openai = None

try:
    import anthropic
except ImportError:
    anthropic = None

# Import dual-model validation system
try:
    from dual_model_service import get_dual_model_service, validate_therapeutic_response, ValidationStatus
    DUAL_MODEL_AVAILABLE = True
except ImportError:
    print("Warning: Dual-model validation not available")
    DUAL_MODEL_AVAILABLE = False

# Load environment variables
load_dotenv()

class OmaniMentalHealthChatbot:
    """
    Enhanced chatbot with dual-model validation for therapeutic-grade responses
    """
    
    def __init__(self):
        self.model_name = "gpt-3.5-turbo"  # Default to most accessible model
        self.temperature = 0.7
        self.language = "English"
        self.max_tokens = 1000
        self.use_dual_validation = True  # Enable dual-model validation
        self.therapeutic_mode = True  # Enable therapeutic enhancements
        
        # Crisis keywords for safety detection
        self.crisis_keywords = [
            "suicide", "kill myself", "end my life", "hurt myself", "self harm",
            "cutting", "overdose", "jump", "hanging", "can't go on", "hopeless",
            "worthless", "better off dead", "Ø§Ù†ØªØ­Ø§Ø±", "Ø£Ù‚ØªÙ„ Ù†ÙØ³ÙŠ", "Ø£Ø¤Ø°ÙŠ Ù†ÙØ³ÙŠ"
        ]
        
        # Initialize LLM
        self._initialize_llm()
        
        # Initialize dual-model service if available
        if DUAL_MODEL_AVAILABLE:
            self.dual_model_service = get_dual_model_service()
        else:
            self.dual_model_service = None
    
    def _initialize_llm(self):
        """Initialize the language model based on current settings"""
        try:
            if "gpt" in self.model_name.lower() and ChatOpenAI:
                # Use LangChain if available
                self.llm = ChatOpenAI(
                    model_name=self.model_name,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                    openai_api_key=os.getenv("OPENAI_API_KEY")
                )
                self.use_langchain = True
            elif "claude" in self.model_name.lower() and ChatAnthropic:
                # Use LangChain if available
                self.llm = ChatAnthropic(
                    model=self.model_name,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                    anthropic_api_key=os.getenv("ANTHROPIC_API_KEY")
                )
                self.use_langchain = True
            elif openai and "gpt" in self.model_name.lower():
                # Fallback to direct OpenAI API
                self.openai_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                self.llm = None  # Will use direct API calls
                self.use_langchain = False
                print("Using direct OpenAI API (LangChain not available)")
            elif anthropic and "claude" in self.model_name.lower():
                # Fallback to direct Anthropic API
                self.anthropic_client = anthropic.Anthropic(
                    api_key=os.getenv("ANTHROPIC_API_KEY")
                )
                self.llm = None  # Will use direct API calls
                self.use_langchain = False
                print("Using direct Anthropic API (LangChain not available)")
            else:
                # Basic fallback
                self.llm = None
                self.use_langchain = False
                print("Warning: No AI service available, using fallback responses")
        except Exception as e:
            self.llm = None
            self.use_langchain = False
            print(f"Warning: Failed to initialize AI service: {str(e)}")
            print("Using fallback responses")
    
    def set_model(self, model_name: str):
        """Set the AI model"""
        self.model_name = model_name
        self._initialize_llm()
    
    def set_temperature(self, temperature: float):
        """Set the creativity level"""
        self.temperature = temperature
        self._initialize_llm()
    
    def set_language(self, language: str):
        """Set the preferred language"""
        self.language = language
    
    def enable_dual_validation(self, enabled: bool = True):
        """Enable or disable dual-model validation"""
        self.use_dual_validation = enabled and DUAL_MODEL_AVAILABLE
    
    def enable_therapeutic_mode(self, enabled: bool = True):
        """Enable or disable therapeutic mode"""
        self.therapeutic_mode = enabled
    
    def get_system_prompt(self) -> str:
        """Get the system prompt based on language preference and therapeutic mode"""
        
        base_prompt = self._get_base_system_prompt()
        
        if self.therapeutic_mode:
            therapeutic_additions = """

THERAPEUTIC ENHANCEMENTS:
- Naturally weave in CBT techniques through conversation (helping them notice thought patterns, exploring feelings)
- Suggest mindfulness and Islamic meditation practices when appropriate
- Share coping strategies as gentle suggestions, not prescriptions
- Always offer hope and help them build resilience through their own strengths
- Continuously watch for signs of crisis, but respond warmly and supportively
- Focus on therapeutic value while maintaining natural conversation flow"""
            
            return base_prompt + therapeutic_additions
        
        return base_prompt
    
    def _get_base_system_prompt(self) -> str:
        """Get base system prompt based on language preference"""
        
        if self.language == "Arabic":
            return """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© Ù…ØµÙ…Ù… Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ©. Ø£Ù†Øª Ù…ØªØ¹Ø§Ø·Ù ÙˆÙ…ØªÙÙ‡Ù… ÙˆÙ…Ø­ØªØ±Ù… Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© ÙˆØ§Ù„ØªÙ‚Ø§Ù„ÙŠØ¯ Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ©.

Ø¥Ø±Ø´Ø§Ø¯Ø§ØªÙƒ:
- ÙƒÙ† Ø¯Ø§ÙØ¦Ø§Ù‹ ÙˆÙ…ØªØ¹Ø§Ø·ÙØ§Ù‹ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø¯ÙˆØ¯
- Ø§Ø­ØªØ±Ù… Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© ÙˆØ§Ù„Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ©
- Ù‚Ø¯Ù… Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ© Ù„Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©
- Ø´Ø¬Ø¹ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ù‡Ù†ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- Ù„Ø§ ØªÙ‚Ø¯Ù… ØªØ´Ø®ÙŠØµØ§Øª Ø·Ø¨ÙŠØ©
- ÙÙŠ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø£Ø²Ù…Ø§ØªØŒ ÙˆØ¬Ù‡ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ÙÙˆØ±ÙŠØ©

ØªØ°ÙƒØ±: Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø§Ø·ÙÙŠ ÙˆÙ„ÙŠØ³ Ø¨Ø¯ÙŠÙ„Ø§Ù‹ Ù„Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…Ù‡Ù†ÙŠØ©."""

        elif self.language == "Both / ÙƒÙ„Ø§Ù‡Ù…Ø§":
            return """You are a mental health support assistant designed for Omani culture. You are empathetic, understanding, and respectful of Islamic values and Omani traditions. Respond in both English and Arabic.

Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© Ù…ØµÙ…Ù… Ù„Ù„Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ©. ÙƒÙ† Ù…ØªØ¹Ø§Ø·ÙØ§Ù‹ ÙˆÙ…ØªÙÙ‡Ù…Ø§Ù‹ ÙˆÙ…Ø­ØªØ±Ù…Ø§Ù‹ Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© ÙˆØ§Ù„ØªÙ‚Ø§Ù„ÙŠØ¯ Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ©.

Your guidelines:
- Be warm and empathetic in all responses
- Respect Islamic values and Omani culture  
- Provide practical mental health advice
- Encourage seeking professional help when needed
- Do not provide medical diagnoses
- In crisis situations, direct to immediate help

Remember: You are a supportive companion, not a replacement for professional medical care."""

        else:  # English
            return """You are a caring mental health companion designed specifically for Omani culture. You are a warm, empathetic friend who understands Islamic values and Omani traditions deeply.

CONVERSATIONAL STYLE:
- Talk like a caring friend, not a formal assistant
- Remember what they've shared before and reference it naturally
- Ask follow-up questions to show you're listening
- Use personal, warm language ("I understand how that feels", "That sounds really difficult")
- Keep responses conversational and flowing, not bullet-pointed lists
- Share gentle observations about their emotions and experiences
- Offer support before solutions

CULTURAL SENSITIVITY:
- Respect Islamic values and Omani culture naturally in conversation
- Reference Islamic concepts like sabr (patience), tawakkul (trust in Allah) when appropriate
- Be sensitive to cultural stigma around mental health
- Suggest culturally appropriate coping strategies (prayer, family support, community involvement)
- Understand the importance of family and community in Omani culture

THERAPEUTIC APPROACH:
- Use evidence-based CBT techniques naturally in conversation
- Help them explore their feelings and thoughts
- Provide gentle guidance and perspective
- Encourage professional help when needed (but not as a list item)
- In crisis situations, provide immediate support and direct to help

Remember: You are a supportive friend having a genuine conversation, not giving a formal consultation. Always remember their previous messages and build on the conversation naturally."""
    
    def get_welcome_message(self) -> str:
        """Get a culturally appropriate welcome message"""
        
        if self.language == "Arabic":
            return """Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆÙ…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… ğŸŒ™

Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø¯Ø¹Ù…ÙƒÙ… ÙÙŠ Ø±Ø­Ù„Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒÙ… ÙÙŠ:
- Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚Ù„Ù‚ ÙˆØ§Ù„ØªÙˆØªØ±
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ÙˆÙ… ÙˆØ§Ù„Ø±Ø§Ø­Ø©
- Ø¥Ø¯Ø§Ø±Ø© Ø¶ØºÙˆØ· Ø§Ù„Ø¹Ù…Ù„
- ØªÙ‚ÙˆÙŠØ© Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©
- ØªØ·ÙˆÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ£Ù‚Ù„Ù…

ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒÙ… Ø§Ù„ÙŠÙˆÙ…ØŸ"""

        elif self.language == "Both / ÙƒÙ„Ø§Ù‡Ù…Ø§":
            return """Peace be upon you and welcome! Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆÙ…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… ğŸŒ™

I'm here to support you on your mental wellness journey. I can help with:
- Managing anxiety and stress | Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚Ù„Ù‚ ÙˆØ§Ù„ØªÙˆØªØ±  
- Improving sleep and rest | ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ÙˆÙ… ÙˆØ§Ù„Ø±Ø§Ø­Ø©
- Work-life balance | Ø¥Ø¯Ø§Ø±Ø© Ø¶ØºÙˆØ· Ø§Ù„Ø¹Ù…Ù„
- Strengthening relationships | ØªÙ‚ÙˆÙŠØ© Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©
- Developing coping strategies | ØªØ·ÙˆÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ£Ù‚Ù„Ù…

How can I support you today? | ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒÙ… Ø§Ù„ÙŠÙˆÙ…ØŸ"""

        else:  # English
            return """Peace be upon you and welcome! ğŸŒ™

I'm here to support you on your mental wellness journey, with deep respect for Omani culture and Islamic values. I can help with:

- Managing anxiety and stress
- Improving sleep and emotional well-being  
- Work-life balance and career stress
- Strengthening family and social relationships
- Developing healthy coping strategies
- Integrating faith-based healing approaches

How can I support you today?"""
    
    def detect_crisis(self, message: str) -> bool:
        """Enhanced crisis detection"""
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in self.crisis_keywords)
    
    def get_crisis_response(self) -> str:
        """Get crisis response with enhanced safety information"""
        
        if self.language == "Arabic":
            return """ğŸš¨ Ø£Ø´Ø¹Ø± Ø¨Ù‚Ù„Ù‚ Ø­ÙˆÙ„ Ù…Ø§ ØªÙ…Ø± Ø¨Ù‡. Ø³Ù„Ø§Ù…ØªÙƒ Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹.

ğŸ‡´ğŸ‡² ÙÙŠ Ø¹ÙÙ…Ø§Ù† - Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙˆØ±ÙŠØ©:
- Ø§Ù„Ø·ÙˆØ§Ø±Ø¦: 9999
- Ù…Ø³ØªØ´ÙÙ‰ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø³Ù„Ø·Ø§Ù† Ù‚Ø§Ø¨ÙˆØ³: 24141414
- Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø³Ù„Ø·Ø§Ù†ÙŠ: 24599000
- Ø®Ø· Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©: 80002020

ğŸŒ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¯ÙˆÙ„ÙŠØ©:
- Ø®Ø· Ø§Ù„Ø£Ø²Ù…Ø§Øª Ø§Ù„Ù†ØµÙŠ: Ø£Ø±Ø³Ù„ HOME Ø¥Ù„Ù‰ 741741

ØªØ°ÙƒØ±: Ø£Ù†Øª Ù„Ø³Øª ÙˆØ­ÙŠØ¯Ø§Ù‹ØŒ ÙˆØ§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù…ØªØ§Ø­Ø©. Ø§Ù„Ù„Ù‡ Ù…Ø¹Ùƒ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø­Ù†Ø©. Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ÙÙˆØ±ÙŠØ©."""

        else:
            return """ğŸš¨ I'm very concerned about what you're going through. Your safety is extremely important.

ğŸ‡´ğŸ‡² In Oman - Immediate Help:
- Emergency: 9999  
- Sultan Qaboos University Hospital: 24141414
- Royal Hospital: 24599000
- Mental Health Helpline: 80002020

ğŸŒ International Support:
- Crisis Text Line: Text HOME to 741741
- International Association for Suicide Prevention: iasp.info

Remember: You are not alone, and help is available. Allah is with you through this trial. Please don't hesitate to seek immediate help."""
    
    def format_conversation_history(self, chat_history: List[Dict]) -> List:
        """Convert chat history to appropriate format"""
        messages = []
        
        if self.use_langchain and self.llm:
            messages.append(SystemMessage(content=self.get_system_prompt()))
            
            for message in chat_history[-10:]:  # Keep last 10 messages for context
                if message['role'] == 'user':
                    messages.append(HumanMessage(content=message['content']))
                elif message['role'] == 'assistant':
                    messages.append(AIMessage(content=message['content']))
        else:
            # For direct API calls
            messages.append({"role": "system", "content": self.get_system_prompt()})
            
            for message in chat_history[-10:]:
                if message['role'] in ['user', 'assistant']:
                    messages.append({
                        "role": message['role'],
                        "content": message['content']
                    })
        
        return messages
    
    async def get_response_async(self, user_input: str, chat_history: List[Dict] = None, conversation_id: str = None) -> Dict[str, Any]:
        """Get AI response with optional dual-model validation"""
        import time
        start_time = time.time()
        
        # Check for crisis first
        crisis_detected = self.detect_crisis(user_input)
        
        if crisis_detected:
            crisis_response = self.get_crisis_response()
            
            # For crisis, always use dual validation if available
            if self.dual_model_service and self.use_dual_validation:
                try:
                    validation_result = await validate_therapeutic_response(user_input, chat_history)
                    combined_response = f"{crisis_response}\n\n---\n\n{validation_result.final_response}"
                    
                    return {
                        "response": combined_response,
                        "crisis_detected": True,
                        "safety_info": {
                            "emergency_number": "9999",
                            "crisis_helplines": ["Sultan Qaboos University Hospital: 24141414", "Royal Hospital: 24599000"],
                            "message": "Emergency support available 24/7"
                        },
                        "response_time": time.time() - start_time,
                        "conversation_id": conversation_id,
                        "therapeutic_grade": validation_result.therapeutic_grade,
                        "validation_status": validation_result.validation_status.value,
                        "consensus_score": validation_result.consensus_score,
                        "dual_model_used": True
                    }
                except Exception as e:
                    print(f"Dual validation failed for crisis: {e}")
            
            # Fallback for crisis without dual validation
            regular_response = self._get_regular_response(user_input, chat_history)
            combined_response = f"{crisis_response}\n\n---\n\n{regular_response}"
            
            return {
                "response": combined_response,
                "crisis_detected": True,
                "safety_info": {
                    "emergency_number": "9999",
                    "crisis_helplines": ["Sultan Qaboos University Hospital: 24141414", "Royal Hospital: 24599000"],
                    "message": "Emergency support available 24/7"
                },
                "response_time": time.time() - start_time,
                "conversation_id": conversation_id,
                "dual_model_used": False
            }
        
        # Non-crisis responses with optional dual validation
        if self.dual_model_service and self.use_dual_validation and self.therapeutic_mode:
            try:
                validation_result = await validate_therapeutic_response(user_input, chat_history)
                
                return {
                    "response": validation_result.final_response,
                    "crisis_detected": False,
                    "safety_info": validation_result.safety_assessment,
                    "response_time": time.time() - start_time,
                    "conversation_id": conversation_id,
                    "therapeutic_grade": validation_result.therapeutic_grade,
                    "validation_status": validation_result.validation_status.value,
                    "consensus_score": validation_result.consensus_score,
                    "recommendations": validation_result.recommendations,
                    "dual_model_used": True,
                    "validation_time": validation_result.validation_time
                }
            except Exception as e:
                print(f"Dual validation failed: {e}")
                # Fall back to regular response
        
        # Regular response without dual validation
        regular_response = self._get_regular_response(user_input, chat_history)
        
        return {
            "response": regular_response,
            "crisis_detected": False,
            "safety_info": {},
            "response_time": time.time() - start_time,
            "conversation_id": conversation_id,
            "dual_model_used": False
        }
    
    def get_response(self, user_input: str, chat_history: List[Dict] = None, conversation_id: str = None) -> Dict[str, Any]:
        """Synchronous wrapper for get_response_async"""
        
        # Check if we're already in an async context
        try:
            loop = asyncio.get_running_loop()
            # We're in an async context, but this is a sync call
            # Create a new task for the async operation
            task = asyncio.create_task(self.get_response_async(user_input, chat_history, conversation_id))
            return asyncio.run_coroutine_threadsafe(task, loop).result()
        except RuntimeError:
            # No running loop, safe to create new one
            return asyncio.run(self.get_response_async(user_input, chat_history, conversation_id))
    
    def _get_regular_response(self, user_input: str, chat_history: List[Dict] = None) -> str:
        """Get regular AI response (existing implementation)"""
        try:
            if self.use_langchain and self.llm:
                # Use LangChain approach
                if chat_history:
                    messages = self.format_conversation_history(chat_history)
                else:
                    messages = [SystemMessage(content=self.get_system_prompt())]
                
                # Add current user message
                messages.append(HumanMessage(content=user_input))
                
                # Get response from LLM
                response = self.llm(messages)
                
                # Extract content based on response type
                if hasattr(response, 'content'):
                    return response.content
                else:
                    return str(response)
            
            elif not self.use_langchain and hasattr(self, 'openai_client') and "gpt" in self.model_name.lower():
                # Direct OpenAI API call (v1.0+ format)
                messages = [
                    {"role": "system", "content": self.get_system_prompt()},
                ]
                
                # Add chat history
                if chat_history:
                    for msg in chat_history[-10:]:  # Last 10 messages
                        if msg['role'] in ['user', 'assistant']:
                            messages.append({
                                "role": msg['role'],
                                "content": msg['content']
                            })
                
                # Add current message
                messages.append({"role": "user", "content": user_input})
                
                # Make API call with fallback
                try:
                    response = self.openai_client.chat.completions.create(
                        model=self.model_name,
                        messages=messages,
                        temperature=self.temperature,
                        max_tokens=self.max_tokens
                    )
                    return response.choices[0].message.content
                    
                except Exception as model_error:
                    # Check if it's a model access error
                    if "model_not_found" in str(model_error) or "does not have access" in str(model_error):
                        print(f"Model {self.model_name} not accessible, falling back to gpt-3.5-turbo")
                        # Fallback to gpt-3.5-turbo
                        response = self.openai_client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=messages,
                            temperature=self.temperature,
                            max_tokens=self.max_tokens
                        )
                        # Update the model for future calls
                        self.model_name = "gpt-3.5-turbo"
                        return response.choices[0].message.content
                    else:
                        raise model_error
            
            elif not self.use_langchain and hasattr(self, 'anthropic_client') and "claude" in self.model_name.lower():
                # Direct Anthropic API call
                system_prompt = self.get_system_prompt()
                
                # Format conversation for Anthropic
                conversation = ""
                if chat_history:
                    for msg in chat_history[-10:]:  # Last 10 messages
                        if msg['role'] == 'user':
                            conversation += f"Human: {msg['content']}\n\n"
                        elif msg['role'] == 'assistant':
                            conversation += f"Assistant: {msg['content']}\n\n"
                
                conversation += f"Human: {user_input}\n\nAssistant:"
                
                # Make API call
                response = self.anthropic_client.completions.create(
                    model=self.model_name,
                    prompt=f"{system_prompt}\n\n{conversation}",
                    temperature=self.temperature,
                    max_tokens_to_sample=self.max_tokens
                )
                
                return response.completion.strip()
            
            else:
                # Fallback response when no AI service is available
                return self._get_fallback_response("No AI service initialized")
                
        except Exception as e:
            return self._get_fallback_response(str(e))
    
    def _get_fallback_response(self, error: str) -> str:
        """Provide a helpful fallback response when AI fails"""
        
        if self.language == "Arabic":
            return """Ø£Ø¹ØªØ°Ø±ØŒ Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ØªÙ‚Ù†ÙŠØ© ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ. 

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø«Ù†Ø§Ø¡ØŒ Ø¥Ù„ÙŠÙƒ Ø¨Ø¹Ø¶ Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ù…ÙÙŠØ¯Ø©:
- Ø®Ø° Ù†ÙØ³Ø§Ù‹ Ø¹Ù…ÙŠÙ‚Ø§Ù‹ ÙˆØ§Ø³ØªØ±Ø®Ù
- ØªØ°ÙƒØ± Ø£Ù† Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ù…Ø¤Ù‚ØªØ©
- ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø£Ø­Ø¨Ø§Ø¦Ùƒ
- Ø§Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ù‡Ù†ÙŠØ© Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¨Ø­Ø§Ø¬Ø© Ù„Ù‡Ø§

Ø³Ø£Ø­Ø§ÙˆÙ„ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù‚Ø±ÙŠØ¨Ø§Ù‹."""

        else:
            return f"""I apologize, but I'm experiencing a technical difficulty right now. 

In the meantime, here are some helpful reminders:
- Take a deep breath and try to relax
- Remember that difficult times are temporary  
- Reach out to loved ones for support
- Consider professional help if you need it
- Practice self-care and be patient with yourself

I'll try to help you again soon. Error details: {error}"""
    
    def get_service_status(self) -> Dict[str, Any]:
        """Get comprehensive service status"""
        status = {
            "basic_chatbot": self.llm is not None or hasattr(self, 'openai_client') or hasattr(self, 'anthropic_client'),
            "model_name": self.model_name,
            "language": self.language,
            "therapeutic_mode": self.therapeutic_mode,
            "dual_validation_enabled": self.use_dual_validation,
            "dual_model_available": DUAL_MODEL_AVAILABLE
        }
        
        if self.dual_model_service:
            dual_status = self.dual_model_service.get_service_status()
            status.update({
                "dual_model_status": dual_status
            })
        
        return status
    
    def get_mental_health_tips(self) -> List[str]:
        """Get general mental health tips"""
        
        if self.language == "Arabic":
            return [
                "Ù…Ø§Ø±Ø³ Ø§Ù„ØµÙ„Ø§Ø© ÙˆØ§Ù„Ø°ÙƒØ± Ù„Ù„Ø±Ø§Ø­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©",
                "Ø§Ø­ØªÙØ¸ Ø¨Ø±ÙˆØªÙŠÙ† ÙŠÙˆÙ…ÙŠ Ù…Ù†ØªØ¸Ù…",
                "Ù…Ø§Ø±Ø³ Ø§Ù„Ø±ÙŠØ§Ø¶Ø© Ø¨Ø§Ù†ØªØ¸Ø§Ù…",
                "ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø£Ù‡Ù„ ÙˆØ§Ù„Ø£ØµØ¯Ù‚Ø§Ø¡",
                "Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù†ÙˆÙ… ÙƒØ§ÙÙ",
                "ØªÙ†Ø§ÙˆÙ„ Ø·Ø¹Ø§Ù…Ø§Ù‹ ØµØ­ÙŠØ§Ù‹",
                "Ù…Ø§Ø±Ø³ Ø§Ù„Ø§Ù…ØªÙ†Ø§Ù† ÙˆØ§Ù„ØªØ£Ù…Ù„"
            ]
        else:
            return [
                "Practice regular prayer and dhikr for spiritual peace",
                "Maintain a consistent daily routine",
                "Engage in regular physical exercise",
                "Stay connected with family and friends",
                "Get adequate sleep (7-9 hours)",
                "Eat nutritious, balanced meals",
                "Practice gratitude and mindfulness",
                "Seek professional help when needed"
            ] 