# ===== Omani Mental Health Voice-Enabled Chatbot Configuration =====

# Core AI Model Settings
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Azure Speech Services Configuration (Required for Voice Interface)
AZURE_SPEECH_KEY=your_azure_speech_service_key_here
AZURE_SPEECH_REGION=your_azure_speech_region_here
AZURE_SPEECH_ENDPOINT=https://your-region.api.cognitive.microsoft.com/

# Voice Interface Settings
VOICE_LANGUAGE=ar-OM  # Omani Arabic
VOICE_FALLBACK_LANGUAGE=ar-SA  # Saudi Arabic (closest dialect)
VOICE_OUTPUT_LANGUAGE=ar-OM  # Omani Arabic output
TTS_VOICE_NAME=ar-OM-AyshaNeural  # Female Omani voice
STT_LANGUAGE=ar-OM  # Speech-to-text language

# Performance Settings for Real-time Voice
MAX_RESPONSE_TIME=20  # Maximum response time in seconds
VOICE_BUFFER_SIZE=1024  # Audio buffer size
WEBSOCKET_TIMEOUT=30  # WebSocket connection timeout

# Application Settings
STREAMLIT_PORT=8501
APP_TITLE=Omani Mental Health Voice Assistant - المساعد النفسي العماني
CRISIS_HELPLINE=9999  # Oman Emergency Services

# Advanced Voice Features
ENABLE_REAL_TIME_PROCESSING=true
ENABLE_VOICE_EMOTIONS=true
ENABLE_CULTURAL_SPEECH_PATTERNS=true
VOICE_QUALITY=high  # high, medium, low

# Development/Testing
DEBUG_MODE=false
LOG_VOICE_INTERACTIONS=false  # Set to true for development only
SAVE_AUDIO_FILES=false  # Set to true for debugging only 